/**
 * AUTO-GENERATED FILE - DO NOT EDIT
 * Generated by: bun scripts/embed-assets.ts
 * Generated at: 2025-12-12T04:08:22.671Z
 *
 * Embedded rule templates for use in compiled binaries.
 */

export const EMBEDDED_RULES: Record<string, string> = {
  "00-overview": `# Long-Task Harness

This project uses the **agent-foreman** harness for feature-driven development with AI agents.

## Core Files

| File | Purpose |
|------|---------|
| \`ai/feature_list.json\` | Feature backlog with status tracking |
| \`ai/progress.log\` | Session handoff audit log |
| \`ai/init.sh\` | Bootstrap script (install/dev/check) |

## Feature Status Values

- \`failing\` - Not yet implemented or incomplete
- \`passing\` - Acceptance criteria met
- \`blocked\` - External dependency blocking
- \`needs_review\` - Potentially affected by recent changes
- \`failed\` - Implementation attempted but verification failed
- \`deprecated\` - No longer needed

## Feature Selection Priority

When running \`agent-foreman next\`, features are selected in this order:
1. **Status first**: \`needs_review\` > \`failing\` (other statuses excluded)
2. **Then priority number**: Lower number = higher priority (1 is highest)

Example: A feature with \`priority: 1\` runs before \`priority: 10\`
`,
  "03-commands": `# Commands

\`\`\`bash
# View project status
agent-foreman status

# Work on next priority feature
agent-foreman next

# Work on specific feature
agent-foreman next <feature_id>

# Verify feature implementation (without marking complete)
agent-foreman check <feature_id>

# Mark feature as done (skips verification by default, use after check)
agent-foreman done <feature_id>

# Mark feature as done (with verification, for manual use)
agent-foreman done <feature_id> --no-skip-check

# Full mode - run all tests (slower, for final verification)
agent-foreman done <feature_id> --full --no-skip-check

# Skip E2E tests (faster iterations)
agent-foreman done <feature_id> --skip-e2e

# Skip auto-commit (manual commit)
agent-foreman done <feature_id> --no-commit

# Disable loop mode (no continuation reminder)
agent-foreman done <feature_id> --no-loop

# Analyze impact of changes
agent-foreman impact <feature_id>

# Scan project verification capabilities
agent-foreman scan

# Bootstrap/development/testing
./ai/init.sh bootstrap
./ai/init.sh dev
./ai/init.sh check
./ai/init.sh check --quick  # Selective testing mode
\`\`\`
`,
  "04-feature-schema": `# Feature JSON Schema

**IMPORTANT**: When adding or modifying features in \`ai/feature_list.json\`, use this exact schema.

**Note**: \`priority\` uses lower number = higher priority (1 is highest, 10 is lower).

\`\`\`json
{
  "features": [
    {
      "id": "module.feature.action",
      "description": "Human-readable description of the feature",
      "module": "parent-module-name",
      "priority": 1,
      "status": "failing",
      "acceptance": [
        "First acceptance criterion",
        "Second acceptance criterion"
      ],
      "dependsOn": ["other.feature.id"],
      "supersedes": [],
      "tags": ["optional-tag"],
      "version": 1,
      "origin": "manual",
      "notes": "",
      "testRequirements": {
        "unit": { "required": false, "pattern": "tests/module/**/*.test.ts" }
      }
    }
  ],
  "metadata": {
    "projectGoal": "Project goal description",
    "createdAt": "2024-01-01T00:00:00.000Z",
    "updatedAt": "2024-01-01T00:00:00.000Z",
    "version": "1.0.0"
  }
}
\`\`\`

**Required fields**: \`id\`, \`description\`, \`module\`, \`priority\`, \`status\`, \`acceptance\`, \`version\`, \`origin\`

**Auto-generated fields**: \`testRequirements\` (auto-generated during init with pattern \`tests/{module}/**/*.test.*\`)

**Optional fields**: \`testRequirements\` (can be overridden), \`e2eTags\` (Playwright tags for E2E filtering)

## Feature ID Convention

Feature IDs use dot notation: \`module.submodule.action\`

Examples:
- \`auth.login\`
- \`chat.message.edit\`
- \`api.users.create\`

## Acceptance Criteria Format

Write criteria as testable statements:
- "User can submit the form and see a success message"
- "API returns 201 status with created resource"
- "Error message displays when validation fails"

## testRequirements Structure

\`\`\`json
"testRequirements": {
  "unit": {
    "required": false,
    "pattern": "tests/auth/**/*.test.ts",
    "cases": ["should login", "should logout"]
  },
  "e2e": {
    "required": false,
    "pattern": "e2e/auth/**/*.spec.ts",
    "tags": ["@auth"],
    "scenarios": ["user can login"]
  }
}
\`\`\`

- \`required: true\` - Feature cannot complete without matching test files (TDD enforcement)
- \`pattern\` - Glob pattern for selective test execution in quick mode
- \`cases\`/\`scenarios\` - Expected test names (optional, for documentation)

**Status values**: \`failing\` | \`passing\` | \`blocked\` | \`needs_review\` | \`failed\` | \`deprecated\`

**Origin values**: \`init-auto\` | \`init-from-routes\` | \`init-from-tests\` | \`manual\` | \`replan\`

`,
  "02-rules": `# Rules

1. **One feature per session** - Complete or pause cleanly before switching
2. **Don't modify acceptance criteria** - Only change \`status\` and \`notes\`
3. **Update status promptly** - Mark features passing when criteria met
4. **Leave clean state** - No broken code between sessions
5. **Use single-line log format** - One line per entry, not verbose Markdown
6. **Never kill running processes** - Let \`agent-foreman\` commands complete naturally, even if they appear slow or timed out. They may be doing important work (verification, git commits, survey regeneration). Just wait for completion.
7. **Use CI=true for tests** - Always set \`CI=true\` environment variable when running any test commands (e.g., \`CI=true npm test\`, \`CI=true pnpm test\`, \`CI=true vitest\`) to ensure non-interactive mode and consistent behavior.
`,
  "05-tdd": `# TDD Mode - Test-Driven Development

## CRITICAL: AI Agent Instructions

**When \`tddMode: "strict"\` is active, AI agents MUST:**

1. **NEVER write implementation code before tests exist**
2. **ALWAYS create test files FIRST**
3. **ALWAYS verify tests fail before implementing**
4. **ALWAYS verify tests pass after implementing**
5. **NEVER skip the RED ‚Üí GREEN ‚Üí REFACTOR cycle**

**Violation of these rules will cause \`agent-foreman check\` and \`agent-foreman done\` to FAIL.**

---

## TDD Mode Configuration

The project's TDD enforcement is controlled by \`metadata.tddMode\` in \`ai/feature_list.json\`:

| Mode | Effect | AI Agent Behavior |
|------|--------|-------------------|
| \`strict\` | Tests REQUIRED | MUST follow TDD workflow exactly |
| \`recommended\` (default) | Tests suggested | SHOULD follow TDD workflow |
| \`disabled\` | No TDD guidance | MAY skip tests |

---

## Strict Mode Behavior

When \`tddMode: "strict"\`:
- \`agent-foreman check\` **BLOCKS** if test files are missing
- \`agent-foreman done\` **BLOCKS** if test files are missing
- All features auto-migrate to \`testRequirements.unit.required: true\`
- TDD workflow is **MANDATORY**, not optional

---

## The TDD Cycle: RED ‚Üí GREEN ‚Üí REFACTOR

### Phase 1: RED (Write Failing Tests)

**DO THIS FIRST. No implementation code yet.**

1. Read the acceptance criteria from \`agent-foreman next\` output
2. Create test file at the suggested path
3. Write one test for each acceptance criterion
4. Run tests: \`CI=true <your-test-command>\` (e.g., npm test, pnpm test, vitest)
5. **Verify tests FAIL** - this proves tests are checking the right thing

\`\`\`typescript
// Example: tests/auth/login.test.ts
describe('auth.login', () => {
  it('should authenticate user with valid credentials', () => {
    const result = login('user@example.com', 'password123');
    expect(result.success).toBe(true);
    expect(result.token).toBeDefined();
  });

  it('should reject invalid credentials', () => {
    const result = login('user@example.com', 'wrong');
    expect(result.success).toBe(false);
    expect(result.error).toBe('Invalid credentials');
  });
});
\`\`\`

### Phase 2: GREEN (Make Tests Pass)

**Now write implementation code.**

1. Write the MINIMUM code to make tests pass
2. Do not add extra features
3. Do not optimize prematurely
4. Run tests: \`CI=true <your-test-command>\`
5. **Verify ALL tests PASS**

### Phase 3: REFACTOR (Improve Code Quality)

**Clean up while tests protect you.**

1. Improve naming, structure, readability
2. Remove duplication
3. Apply design patterns if appropriate
4. Run tests after EACH change: \`CI=true <your-test-command>\`
5. **Tests MUST remain passing**

---

## Test File Locations

When \`agent-foreman next\` shows TDD guidance, it suggests test file paths:

\`\`\`
üìù Suggested Test Files:
   Unit: tests/module/feature.test.ts
   E2E:  e2e/module/feature.spec.ts
\`\`\`

**ALWAYS use these suggested paths** - they match the patterns in \`testRequirements\`.

---

## Verification Gates

### Before Implementation

The AI agent MUST verify:
- [ ] Test file exists at suggested path
- [ ] Tests cover ALL acceptance criteria
- [ ] Tests FAIL when run (RED phase complete)

### After Implementation

The AI agent MUST verify:
- [ ] All tests PASS
- [ ] No test was modified to make it pass artificially
- [ ] Implementation satisfies the original acceptance criteria

### Command Verification

\`\`\`bash
# Check that tests exist and implementation is correct
agent-foreman check <feature_id>

# If check passes, complete the feature
agent-foreman done <feature_id>
\`\`\`

---

## User Control via Natural Language

| User Says | Action |
|-----------|--------|
| "enable strict TDD" / "require tests" | Set \`tddMode: "strict"\` |
| "disable strict TDD" / "optional tests" | Set \`tddMode: "recommended"\` |
| "turn off TDD" | Set \`tddMode: "disabled"\` |

To change mode manually, edit \`ai/feature_list.json\`:
\`\`\`json
{
  "metadata": {
    "tddMode": "strict"
  }
}
\`\`\`

---

## Common Mistakes to Avoid

### ‚ùå WRONG: Implementation First

\`\`\`
1. Read acceptance criteria
2. Write implementation code  ‚Üê WRONG! Tests don't exist yet
3. Write tests that pass
4. Done
\`\`\`

### ‚úÖ CORRECT: Tests First

\`\`\`
1. Read acceptance criteria
2. Write tests for each criterion
3. Run tests - verify they FAIL
4. Write implementation code
5. Run tests - verify they PASS
6. Refactor if needed
7. Done
\`\`\`

---

## Why TDD Matters

1. **Tests verify the right behavior** - Writing tests first ensures you understand the requirements
2. **Prevents over-engineering** - You only write code to pass tests
3. **Enables safe refactoring** - Tests catch regressions immediately
4. **Documents behavior** - Tests serve as executable specifications
5. **Catches bugs early** - Failing tests reveal problems before deployment
`,
  "06-progress-log": `# Progress Log Format

Append entries to \`ai/progress.log\` using this **single-line format only**:

\`\`\`
2025-01-15T10:30:00Z STEP feature=auth.login status=passing summary="Implemented login flow"
2025-01-15T11:00:00Z CHANGE feature=auth.login action=refactor reason="Improved error handling"
2025-01-15T12:00:00Z REPLAN summary="Splitting auth into submodules" note="Original scope too large"
\`\`\`

**Log types**: \`INIT\` | \`STEP\` | \`CHANGE\` | \`REPLAN\` | \`VERIFY\`

**IMPORTANT**: Do NOT write verbose Markdown session notes. Keep each entry as a single line.
`,
  "01-workflow": `# Workflow for Each Session

## Mode Detection

**If a feature_id is provided** (e.g., \`agent-foreman next auth.login\`):
- Work on that specific feature only
- Complete it and stop

**If no feature_id** (e.g., \`agent-foreman next\`):
- Auto-select highest priority pending feature
- Process features in priority order

---

## IMPORTANT: TDD Mode Check

Before implementing ANY feature, check if strict TDD mode is active:
- Look for \`!!! TDD ENFORCEMENT ACTIVE !!!\` in \`agent-foreman next\` output
- Or check \`ai/feature_list.json\` for \`"tddMode": "strict"\`

**If TDD mode is strict ‚Üí MUST follow TDD Workflow below**
**If TDD mode is recommended/disabled ‚Üí May follow Standard Workflow**

---

## TDD Workflow (MANDATORY when tddMode: strict)

**AI agents MUST follow these steps EXACTLY in order. DO NOT skip any step.**

\`\`\`bash
# STEP 1: Get feature and TDD guidance
agent-foreman next <feature_id>
# Read the TDD GUIDANCE section carefully
# Note the suggested test files and test cases
\`\`\`

### STEP 2: RED - Write Failing Tests FIRST

**This step is MANDATORY. DO NOT write implementation code yet.**

1. Create test file at the suggested path (e.g., \`tests/module/feature.test.ts\`)
2. Write test cases for EACH acceptance criterion
3. Run tests to verify they FAIL:
   \`\`\`bash
   CI=true <your-test-command>  # e.g., npm test, pnpm test, yarn test, vitest
   \`\`\`
4. **Tests MUST fail** - this confirms tests are valid and testing the right thing

Example test structure:
\`\`\`typescript
describe('feature-name', () => {
  it('should satisfy acceptance criterion 1', () => {
    // Test implementation
    expect(result).toBe(expected);
  });

  it('should satisfy acceptance criterion 2', () => {
    // Test implementation
  });
});
\`\`\`

### STEP 3: GREEN - Implement Minimum Code

**Only now may you write implementation code.**

1. Write the MINIMUM code needed to pass tests
2. Do not add extra features or optimizations yet
3. Run tests to verify they PASS:
   \`\`\`bash
   CI=true <your-test-command>
   \`\`\`
4. **All tests MUST pass** before proceeding

### STEP 4: REFACTOR - Clean Up Under Test Protection

1. Improve code structure, naming, readability
2. Remove duplication
3. Run tests after EACH change to ensure they still pass:
   \`\`\`bash
   CI=true <your-test-command>
   \`\`\`
4. **Tests MUST remain passing** throughout refactoring

### STEP 5: Verify and Complete

\`\`\`bash
# Verify implementation meets all criteria
agent-foreman check <feature_id>

# If check passes, complete the feature
agent-foreman done <feature_id>
\`\`\`

---

## Standard Workflow (when tddMode: recommended or disabled)

### Single Feature Mode

When feature_id is provided:

\`\`\`bash
# STEP 1: Get the specified feature
agent-foreman next <feature_id>

# STEP 2: Implement feature
# (satisfy ALL acceptance criteria shown)

# STEP 3: Verify implementation (required)
agent-foreman check <feature_id>

# STEP 4: Complete feature (skips re-verification since we just checked)
agent-foreman done <feature_id>
\`\`\`

### All Features Mode

When no feature_id:

\`\`\`bash
# STEP 1: Check status
agent-foreman status

# STEP 2: Get next feature
agent-foreman next

# STEP 3: Implement feature
# (satisfy ALL acceptance criteria shown)

# STEP 4: Verify implementation (required)
agent-foreman check <feature_id>

# STEP 5: Complete feature (skips re-verification since we just checked)
agent-foreman done <feature_id>

# STEP 6: Handle result
# - Verification passed? ‚Üí Continue to STEP 1
# - Verification failed? ‚Üí Mark as failed, continue to STEP 1
# - All features processed? ‚Üí STOP, show summary
\`\`\`

---

## Rules (MUST Follow)

| Rule | Action |
|------|--------|
| TDD mode strict? | MUST follow TDD Workflow (RED ‚Üí GREEN ‚Üí REFACTOR) |
| No skipping | Always: status ‚Üí next ‚Üí implement ‚Üí check ‚Üí done |
| One at a time | Complete current before next |
| No editing criteria | Implement exactly as specified |
| Never kill processes | Let commands finish naturally |

---

## On Verification Failure

When \`agent-foreman done\` reports verification failure:

1. **DO NOT STOP** - Continue to the next feature
2. Mark the failed feature as \`failed\`:
   - Edit \`ai/feature_list.json\`
   - Change \`"status": "failing"\` to \`"status": "failed"\`
   - Add to notes: \`"Verification failed: [reason from output]"\`
3. Log the failure in \`ai/progress.log\`:
   \`\`\`
   YYYY-MM-DDTHH:MM:SSZ VERIFY feature=<id> verdict=fail summary="Marked as failed"
   \`\`\`
4. Continue to the next feature immediately

**CRITICAL: NEVER stop due to verification failure - always mark as \`failed\` and continue!**

---

## Exit Conditions

| Condition | Action |
|-----------|--------|
| All features processed | ‚úÖ STOP - Show summary |
| Single feature completed | ‚úÖ STOP - Feature done |
| User interrupts | ‚èπÔ∏è STOP - Clean state |

---

## Loop Completion

When all features have been processed:

1. Run \`agent-foreman status\` to show final summary
2. Report counts:
   - ‚úì X features passing
   - ‚ö° Y features failed (need investigation)
   - ‚ö† Z features needs_review (dependency changes)
   - ‚úó W features still failing (not attempted)
3. List features that failed verification with their failure reasons

---

## Priority Order (Auto-Selected)

1. \`needs_review\` ‚Üí highest priority
2. \`failing\` ‚Üí next priority
3. Lower \`priority\` number within same status
`
};

export const EMBEDDED_RULE_NAMES = Object.keys(EMBEDDED_RULES);
